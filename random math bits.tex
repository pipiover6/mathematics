\documentclass[english]{article}
	\usepackage[latin9]{inputenc}
	\usepackage{geometry}
	\geometry{verbose,tmargin=2cm,bmargin=2cm,lmargin=2cm,rmargin=2cm}
	\setlength{\parindent}{0bp}
	\usepackage{mathrsfs}
	\usepackage{amsmath}
	\usepackage{setspace}
	\usepackage{esint}
	\usepackage{marginnote}
	\usepackage{hyperref}
	\usepackage{mathpazo} % font %
	\usepackage{eulervm} % font %
	\usepackage{MnSymbol}
	\usepackage{xcolor}
	\usepackage{outlines}
	\usepackage{graphicx}
	\usepackage{mathtools}
	\def\d{\text{d}}
	\def\lap{\Delta}
	\def\id{\text{id}}
	\def\hlf{\frac{1}{2}}
	\newcommand\norm[1]{\left\Vert {#1}\right\Vert }
	\renewcommand\to{\longrightarrow}
	\def\eps{\varepsilon}
	\def\sub{\subseteq}
	\def\subn{\subset}
	\def\C{\mathbf{C}}
	\def\Z{\mathbf{Z}}
	\def\F{\mathbf{F}}
	\def\R{\mathbf{R}}
	\def\disp{\displaystyle}
	\newcommand\floor[1]{\lfloor{#1}\rfloor}
	\graphicspath{ {./imgs/} }
	\newcommand\cyan[1]{{\color{blue}{#1}}}
	\newcommand\orange[1]{{\color{orange}{#1}}}
	\newcommand\red[1]{{\color{red}{#1}}}
	\newcommand\task{\red{Task. }}
	\newcommand{\qed}{$\hfill\blacksquare$}
	\newcommand{\SubItem}[1]{
    	{\setlength\itemindent{15pt} \item[-] #1 }}
	\newcommand\syl[1]{$\text{Sylow}_{#1}$}
	\def\ord{\text{ord}}
	\def\lcm{\text{lcm}}
	\def\perm{\text{Perm}}
	\def\cay{\text{Cay}}
	\def\fgrp{\text{Grp}_{\text{f}}}
	\def\sgn{\text{sgn}}
	\newcommand\set[1]{\{#1\}}
	\def\img{\text{img}}
	\newcommand\abs[1]{\left|#1\right|}
	\DeclareMathOperator\End{End}
	\DeclareMathOperator\Lin{Lin}
	\DeclareMathOperator\GL{GL}
	\DeclareMathOperator\vol{vol}
	\DeclareMathOperator\trace{trace}
\begin{document}
\section*{misc}
Definition. A (mathematical) juggling pattern is a permutation $f:\Z\to\Z$ for which $\d f(t)=f(t)-t\ge 0$.\\


We think of $t\in \Z$ as a discrete, infinite in both directions time parameter. If there is no "throw" at time $t$, we set $f(t)=t$, and otherwise we set $f(t)$ to be the next time the "ball" thrown at $t$ will be thrown again. We think of $\d f(t)$ as the "height" of the throw. This model assumes only one ball may be thrown at once.\\


Observation. Each orbit is either a fixed point (no throw) or infinite in both directions.\\


The "balls" are in one to one correspondence with the infinite orbits.\\


Observation. If $\d f$ is bounded by $M$ then so is the number of balls.\\


What does $\sum_{t\in I}\d f(t)$ count for an interval $I$? well, it counts the "skips" of one ball over another. Approximately, if $I$ is very large, this equals $\abs{I}$ times the number of balls, since each time frame is "skipped over" once by each ball. Another way to see this is the following. The sum of $\d f$ over a ball's orbit in an interval is the last after minus first appearence in that interval, which is $|I| \pm O(M)$.

\section*{combinatorics in finite vector spaces}
In this chapter $F$ is a finite field with $q$ elements and all vector spaces are over $F$ and finite dimensional.\\\\


Result. $\abs{V}=q^{\dim V}$.\\\\


Result. Given a linear surjective mapping $T:V\to W$, $T$ is $\abs{\ker T}:1$.\\\\


Exercise. Given a random coloring of the $30$ edges of the icosahedron red green and blue, what is the probability that each of the $20$ triangular faces have two edges of one color and one edge of another color?\\\\


Result. The number of bases of $V$ is $b_d=(q^d-1)(q^d-q)\dots (q^d-q^{d-1})$, where $d=\dim V$.\\\\


Result. The number of subspaces of $V$ of dimension $k$ is $\dfrac{(q^d-1)(q^d-q)\dots (q^d-q^{k-1})}{(q^k-1)(q^k-q)\dots (q^k-q^{k-1})}=\small{\left[\begin{array}{c}
d\\
k
\end{array}\right]}_{q}$.\\\\


Result. The number of pairs $(U,W)$ with $U\oplus W=V$ and $\dim U=k$ is $\dfrac{b_d}{b_k b_{d-k}}$.\\\\


Result. The number of $T\in\End V$ such that $\ker T\oplus \img T =V$ and $\dim\ker T=k$ is $\dfrac{b_d}{b_k}$.\\\\


Result. Given $U\le V$ of dimension $r$, the number of pairs $(W_1,W_2)$ with $W_1\plus W_2=V$, $W_1\cap W_2=U$ and $\dim W_1=r+j$ is $\dfrac{b_{d-r}}{b_j, b_{d-r-j}}$.\\\\


Result. The number of $T\in\End V$ such that $\dim (\ker T\cap \img T)=r$ and $\dim \img T=r+j$ is $\left[\begin{array}{c}
d\\
d-r
\end{array}\right]_{q}\left[\begin{array}{c}
d-r\\
r
\end{array}\right]_{q}\dfrac{b_{d-2r}b_{j+r}}{b_{j}b_{d-2r-j}}$.\\\\


Result. $q^{d^2}=\disp \sum_{r=0}^{\floor{d/2}}\sum_{j=0}^{d-2r}\left[\begin{array}{c}
d\\
d-r
\end{array}\right]_{q}\left[\begin{array}{c}
d-r\\
r
\end{array}\right]_{q}\dfrac{b_{d-2r}b_{j+r}}{b_{j}b_{d-2r-j}}$\\\\


Result. The expected value of the number of nonzero fixed points of a random $g\in \GL_d(F)$ in $F^d$ is one.\\\\	%Burnside




\section*{random abstract algebra bits}


Exercise. Given an operator $T\in\Lin(V)$ if $v_0,Tv_0,\dots,T^{d-1}v_0$ is a basis of $V$ for some $v_0$, then $ST=TS\iff S$ is a polynomial in $T$.\\


Observation. The following are equivalent for a finite group $G$.
\begin{itemize}
\item The composition $G\xrightarrow{\cay}\perm(G)\xrightarrow{\sgn}\{\pm1\}$ is non-trivial.
\item $2\mid \ord(G)$ and $G$ has an element of order $2^{\nu_2(\ord(G))}$.
\item $2\mid \ord(G)$ and $G$'s \syl{2} subgroups are cyclic.
\\
\end{itemize} 
Corollary. Let $G$ be a finite group. Then the set elements of odd order $O$ forms a subgroup, under the assumption that $G$ has an element of order $2^{\nu_2(\ord(G))}$. Moreover, $[G:O]=2^{\nu_2(\ord(G))}$.
\\\\
Proof. Write $\ord(G)=2^k(2\ell-1)$. The case $k=0$ is trivial. If $k\ge1$, then the composition $G\to\perm(G)\to\set{\pm1}$ is non-trivial. Thus $G$ has a normal subgroup $N$ of index $2$. We have $\ord(N)=2^{k-1}(2\ell-1)$, $O_G=O_N$, and $N$ has an element of order $2^{k-1}$. q.e.d.
\\\\
Observation. Let $M$ be a semi-group of $n$ elements. Then $m^{\lcm(1,\dots,n)}=m^{2\lcm(1,\dots,n)}$ for all $m\in M$.
\\\\
Corollary. Let $A\in\Z^{n\times n}$ be a $k$-th power of an integral matrix for all $k\ge 2$. Then $A=A^2=A^3=\dots$
\\\\
Proof. It suffices to show $A=A^2$ when reduced mod $p$ for each prime $p$. However, working in $M=\F_p^{n\times n}$ we have $\bar{A}={X}^{\lcm(1,\dots,p^{n^2})}$ which implies $\bar{A}=\bar{A}^2$.
\\\\



A bashing proof of theorema egregium. Let $X=X(u,v):D\sub\R^2\overset{\sim}{\to}S\subn \R^3$ be a surface parametrization. Let $$N=\dfrac{X_u\times X_v}{\norm{X_u\times X_v}}$$ be the normal, and
$$\left(\begin{array}{cc}
E & F\\
F & G
\end{array}\right)=\left(\begin{array}{cc}
X_{u}\cdot X_{u} & X_{u}\cdot X_{v}\\
X_{u}\cdot X_{v} & X_{v}\cdot X_{v}
\end{array}\right)$$ be the first fundamental form, namely the surface isometry invariant. To compute the partials of the first fundamental form entries we write
$$\begin{array}{ccc}
X_{uu} =\alpha X_{u} + \beta X_{v} + eN\\\\
X_{uv} = \eps X_{u} + \zeta X_{v} + fN\\\\
X_{vv} = \gamma X_{u} + \delta X_{v} + gN
\end{array}$$\\
Then we have
%$$
%\begin{array}{ccccc}
%X_{uu} & = & \alpha X_{u} + & \beta X_{v} + & eN\\
%X_{vv} & = & \gamma X_{u} + & \delta X_{v} + & gN\\
%X_{uv} & = & \eps X_{u} + & \zeta X_{v} + & fN
%\end{array}
%$$
%\\
$$
\begin{array}{c}
E_{u} = 2(\alpha E+\beta F)\\\\
E_{v} = 2(\eps E+\zeta F)\\\\
G_{u} = 2(\eps F+\zeta G)\\\\
G_{v}  =  2(\gamma F+\delta G)\\\\
F_u=\alpha F + \beta G + \eps E  + \zeta F\\\\
F_v = \gamma E + \delta F + \eps F + \zeta G\\
\end{array}
$$\\
Which mean
$$\begin{array}{c}
\left(\begin{array}{cc}
E & F\\
F & G
\end{array}\right)\left(\begin{array}{c}
\eps\\
\zeta
\end{array}\right)=\hlf\left(\begin{array}{c}
E_{v}\\
G_{u}
\end{array}\right)\\\\
\left(\begin{array}{cc}
E & F\\
F & G
\end{array}\right)\left(\begin{array}{c}
\alpha\\
\beta
\end{array}\right)=\hlf\left(\begin{array}{c}
E_{u}\\
2F_{u}-E_{v}
\end{array}\right)\\\\
\left(\begin{array}{cc}
E & F\\
F & G
\end{array}\right)\left(\begin{array}{c}
\gamma\\
\delta
\end{array}\right)=\hlf\left(\begin{array}{c}
2F_{v}-G_{u}\\
G_{v}
\end{array}\right)
\end{array}$$\\
And so the first fundamental form determines $\alpha,\beta,\gamma,\delta,\eps,\zeta$. Gauss's theorem, which we shall now prove, is that $eg-f^2$ is also determined by the first fundamental form. Firstly, since $N\perp X_u$ and $N\perp X_v$ we have 
$$\begin{array}{c}
e=X_{uu}\cdot N=-N_{u}\cdot X_{u}\\
f=X_{uv}\cdot N=-N_{v}\cdot X_{u}=-N_{u}\cdot X_{v}\\
g=X_{vv}\cdot N=-N_{v}\cdot X_{v}
\end{array}$$
Moreover, since $\norm{N}\equiv 1$ we may write 
$$\begin{array}{c}
N_{u}=a^{11}X_{u}+a^{12}X_{v}\\
N_{v}=a^{21}X_{u}+a^{22}X_{v}
\end{array}$$\\
which yields
$$\left(\begin{array}{cc}
a^{11} & a^{12}\\
a^{21} & a^{22}
\end{array}\right)\left(\begin{array}{cc}
E & F\\
F & G
\end{array}\right)=-\left(\begin{array}{cc}
e & f\\
f & g
\end{array}\right)$$\\
We write $K=a^{11}a^{22}-a^{12}a^{21}=\dfrac{eg-f^2}{EG-F^2}$ for the Gaussian curvature. Now, we have
$$\begin{array}{c}
X_{uuv}=\alpha_{v}X_{u}+\alpha X_{uv}+\beta_{v}X_{v}+\beta X_{vv}+e_{v}N+eN_{v}\\
X_{uvu}=\eps_{u}X_{u}+\eps X_{uu}+\zeta_{u}X_{v}+\zeta X_{uv}+f_{u}N+fN_{u}
\end{array}$$
Comparing the $X_v$ part we get 
$$\alpha\zeta+\beta_{v}+\beta\delta+ea^{22}=\eps\beta+\zeta_{u}+\zeta^{2}+fa^{12}$$
Now, by the matrix equation we have that
$$\eps\beta+\zeta_{u}+\zeta^{2}-\alpha\zeta-\beta_{v}-\beta\delta=ea^{22}-fa^{12}=-EK$$
is determined by the first fundamental form. Since $E$ is positive, $K$ is determined by the first fundamental form.\\
Gauss's theorem, for example, implies that no part of a sphere can be isometrically embedded in the plane. Any map of the globe, no matter of how small a region, will have distorsions.
\\\\
In orthogonal coordinates $E=A^2,F=0,G=B^2$ we get $$K=-\dfrac{1}{AB}\left(\partial_{v}\left(\dfrac{A_{v}}{B}\right)+\partial_{u}\left(\dfrac{B_{u}}{A}\right)\right)$$
In particular, 
in isothermal coordinates $E=G=\lambda$, $F=0$ we have $$K=-\dfrac{\lap \log \lambda}{2\lambda}$$.
\\\\
To me, this finally gives a definition of the curvature of the hyperbolic plane and shows it is $-1$. Indeed, the hyperbolic plane is nothing but $H=\{y>0\}$ with the metric given by $\dfrac{\sqrt{\d x^2+\d y^2}}{y}$. Namely, the first fundamental form is $y^{-2}\id$. This immediately yields $K=-1$.
\\\\
Theorem. $\nu_p(n!)=\floor{n/p}+\floor{n/p^2}+\floor{n/p^3}+\dots$
\\\\
Theorem. $(p-1)\nu_p(n!)=n-s_p(n)$ where $s_p(n)$ is the digit sum of $n$ in base $p$.
\\\\
Theorem. $\nu_p{p^k\choose r}=k-\nu_p(r)$
\\\\
Given $v_1,\dots,v_{n-1}\in\R^n$ linearly independent, how can one find a vector $w$ spanning $(v_1,\dots,v_{n-1})^{\perp}$?\\
Assuming these are row vectors, put them in an $n\times n$ determinant, where the first row is $x_1,\dots,x_n$. \\
This gives a nontrivial linear form in $x$, which vanishes for $x\in\{v_1,\dots,v_{n-1}\}$. It is of course of the form $x\mapsto x\cdot w$ for the $w$ we are looking for. To get $w$ explicitly, note that it's $i$-th coordinate is $e_i\cdot w=\det(e_i,v_1,\dots,v_{n-1})$. Moreover, the length of $w$ is precisely the $n-1$ dimensional volume of the parallelepide spanned by $v_1,\dots,v_{n-1}$. Indeed, $w\cdot w=\det(w,v_1,\dots,v_{n-1})=\vol_{n-1}(v_i)\cdot \norm{w}$, since $w$ is perpendicular to the $v_i$.
\newpage
\section*{Representations of groups}
We start by understanding commutative algebras of matrices. This work is due to Dedekind, Frobenius, Molien, Cartan, Weierstrass.\\\\
The main point is that if $A_1,\dots,A_r\in\C^{d\times d}$ commute then they have a simultaneous triangulaztion. \\
In particular, Dedekind noticed that we have the following factorization to linear terms $$\det(x_1A_1+\dots+x_rA_r)=(\lambda_1^1x_1 +\dots+ \lambda_r^1x_r)\dots (\lambda_1^dx_1 +\dots+ \lambda_r^dx_r)$$ where $\lambda_{j}^1,\dots,\lambda_{j}^d$ are the eigenvalues of $A_j$. More generally, Frobenius noticed that the eigenvalues of $f(A_1,\dots,A_r)$ are $$f(\lambda_1^1,\dots,\lambda_r^1),\dots,f(\lambda_1^d,\dots,\lambda_r^d)$$ for all polynomials $f$ (or even rational functions, as long everything divided by is invertible).
\\\\%this is a corollary of simultaneous triangulization 

Now let $E$ be a commutative and associative algebra with a fixed basis $e_1,\dots,e_d$ over $\C$. Write $$e_je_k=\sum_i \eta_{ijk}e_i$$
Let $A_i\in\C^{d\times d}$ be the matrix of multiplication (left or right) by $e_i$ wrt this basis. Then $$A_jA_k=\sum_i\eta_{ijk}A_i$$ 
This is the (Cayley) regular representation of $E$ into $\End(E)$. Because the $A_i$ commute, they are simultaneously triangulable, so in a triangulazing basis we have $$A_i=\left[\begin{array}{ccc}
\lambda_{i}^{1} & * & *\\
 & \ddots & *\\
 &  & \lambda_{i}^{d}
\end{array}\right]$$
so that $$\lambda_{j}^s\lambda_k^s=\sum_i \eta_{ijk}\lambda_i^s$$
Let's see what happens if $\det(\lambda_j^s)=0$. In that case, there's a nonzero vector $x_1,\dots,x_d$ such that $\lambda_1^sx_1+\dots+\lambda_d^sx_d=0$, namely $x_1A_1+\dots+x_dA_d$ is strictly upper triangular wrt the triangulizing basis. In particular, it is nilpotent, so $x_1e_1+\dots+x_de_d$ is nilpotent, and by commutativity so is any product of it. In particular, it is degenerate in the symmetric bilinear form $(u,v)\mapsto \trace(m_{uv})$. In other words, if this (Killing) form is nondegenerate, then there are no nonzero nilpotents in $E$, which means $\det(\lambda_j^s)\neq 0$. We shall now assume the Killing form is non-degenerate. Since $\det(\lambda_j^s)\neq 0$, we can find linear combinations of the $A_i$ with $\alpha_{1}A_{1}+\dots+\alpha_{s}A_{s}=\left[\begin{array}{ccc}
1 & * & *\\
 & \ddots & *\\
 &  & 0
\end{array}\right]$, ..., $\zeta_{1}A_{1}+\dots+\zeta_{s}A_{s}=\left[\begin{array}{ccc}
0 & * & *\\
 & \ddots & *\\
 &  & 1
\end{array}\right]$. Therefore $\alpha=\sum \alpha_i e_i,\dots,\zeta=\sum \zeta_i e_i$ satisfy that $\alpha^2-\alpha,\dots,\zeta^2-\zeta$ are nilpotent. So $\alpha^2=\alpha,\dots,\zeta^2=\zeta$ are idempotents!!! Moreover, they are clearly a basis of $E$. Moreover, $\alpha\beta,\dots,\alpha\zeta,\dots$ are nilpotents, so zero. So in fact, as an algebra, $E$ is isomorphic to a product of $\C$ with itself $s$ times!!!!!
\\\\

%To see the Killing form is nondegenerate in the case $E=Z(\CG)$, see https://math.stackexchange.com/questions/4631341/reference-for-an-english-translation-of-a-proof-of-frobenius-on-the-origins-of-r


\newpage
\section*{problems}

A two player game with $n$ lamps in a circle is played as follows. In the beginning, player 1 chooses which lamps should be on and which should be off. After that, in each turn, player 2 specifies which lamps should be switched (on$\leftrightarrow$off), but player 1 may rotate the cicle of lamps as they please before making the switches. Player 2 wins once all lamps are off. Find for which $n$ player 2 can win, and how.
\\\\%for powers of 2, R = rotation, then I+R is nilpotent, and so after n turns of specifying the current board player 2 will win

A two player game with a standard deck of cards is played as follows. In the beginning, player 1 randomly shuffles the deck. Then, at any point, player 2 can either bet that the next card will be red, or choose to see the next card. The game ends once the bet is made, and player 2 wins if they guessed right. (Player 2 must make a bet at some point, so if 51 cards were seen the last card has to be betted on). Show that no matter what strategy player 2 picks, they will win an expected $1/2$ of the games they play.
\\\\%two proofs, both think of strategies as binary trees - the first by induction on the number of cards (red and black) and is a simple computation. the second by induction from the leaves: if a parent has both children as leaves they can be merged to the parent. the longest paths are of that form, so the strategy is eventually just picking the first card.

The number of permutations of $[2m]$ all of whose cycles are even (equivalently, odd) is $((2m-1)!!)^2$.
\\\\%this hints towards pfaffians

$\#\{(g_1,g_2):g_1g_2=g_2g_1\}=|G|\cdot k$ where $k=$ num conj classes.



\end{document}
